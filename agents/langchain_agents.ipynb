{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59cd0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "load_dotenv()\n",
    "tavily = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1970a25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 10 threads.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from ingestion import load_documents\n",
    "\n",
    "base_path = os.path.abspath(\"..\")\n",
    "#DOCS = load_documents(base_path)\n",
    "\n",
    "#print(f\"Loaded {len(DOCS)} documents.\") \n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_documents(docs, chunk_size=1000, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunked = []\n",
    "    for doc in docs:\n",
    "        chunks = splitter.split_text(doc[\"text\"])\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunked.append({\n",
    "                \"file\": doc[\"file\"],\n",
    "                \"chunk_id\": i,\n",
    "                \"text\": chunk\n",
    "            })\n",
    "    return chunked\n",
    "\n",
    "DOCS_RAW = load_documents(base_path)       # one entry per file\n",
    "DOCS = chunk_documents(DOCS_RAW)           # one entry per chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1f6c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool  \n",
    "from langchain_openai import ChatOpenAI  \n",
    "from crewai_tools import DOCXSearchTool, WebsiteSearchTool\n",
    "\n",
    "@tool(\n",
    "    \"wordcount_tool\",\n",
    "    description=\"Use this tool ONLY when the user asks for a word count. Input can be a filename or text. If a filename is provided, it must match a loaded document. Returns the exact word count.\"\n",
    ")\n",
    "def wordcount_tool(input_data: str) -> str:\n",
    "    logging.info(\"Tool Word count used\")\n",
    "    for d in DOCS:\n",
    "        if d[\"file\"] == input_data:\n",
    "            return f\"{input_data} word count: {len(d['text'].split())}\"\n",
    "    for d in DOCS:\n",
    "        if input_data.lower() in d[\"file\"].lower():\n",
    "            return f\"{d['file']} word count: {len(d['text'].split())}\"\n",
    "    return f\"Text word count: {len(input_data.split())}\"\n",
    "\n",
    "\n",
    "@tool(\n",
    "    \"websearch_tool\",\n",
    "    description=\"Use this tool when the user asks to search the web in general. Input is a plain natural-language query. Returns extracted results from real online sources.\"\n",
    ")\n",
    "def websearch_tool(query: str) -> str:\n",
    "    logging.info(\"Tool Web Search used (Tavily)\")\n",
    "    try:\n",
    "        result = tavily.search(query, max_results=5)\n",
    "        if not result or \"results\" not in result:\n",
    "            return \"No results found.\"\n",
    "        \n",
    "        formatted = []\n",
    "        for item in result[\"results\"]:\n",
    "            title = item.get(\"title\", \"No title\")\n",
    "            url = item.get(\"url\", \"No URL\")\n",
    "            content = item.get(\"content\", \"\")[:400]  # first 400 chars\n",
    "            formatted.append(f\"- {title}\\n  {url}\\n  {content}\\n\")\n",
    "\n",
    "        return \"\\n\".join(formatted)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error during web search: {e}\"\n",
    "\n",
    "\n",
    "@tool(\n",
    "    \"news_search_tool\",\n",
    "    description=\"Use this tool only when the user asks specifically for news articles. Input is a plain natural-language query. Searches BBC, CNN, Reuters and NYTimes for relevant articles.\"\n",
    ")\n",
    "def news_search_tool(query: str) -> str:\n",
    "    logging.info(\"Tool News Search used\")\n",
    "    search_query = (\n",
    "        f\"site:bbc.com OR site:cnn.com OR site:reuters.com \"\n",
    "        f\"OR site:nytimes.com {query}\"\n",
    "    )\n",
    "    try:\n",
    "        return WebsiteSearchTool().run(search_query) or \"No news results.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error during news search: {e}\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e1412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared cache for DOCXSearchTool instances\n",
    "DOCX_TOOL_CACHE = {}\n",
    "\n",
    "def get_docx_tool(file_path):\n",
    "    if file_path not in DOCX_TOOL_CACHE:\n",
    "        DOCX_TOOL_CACHE[file_path] = DOCXSearchTool(docx=file_path)\n",
    "    return DOCX_TOOL_CACHE[file_path]\n",
    "\n",
    "def resolve_doc_path(name_or_path: str):\n",
    "    needle = name_or_path.strip().strip(\"'\").strip('\"').lower()\n",
    "    for d in DOCS_RAW:\n",
    "        path = d[\"file\"]\n",
    "        if needle == os.path.basename(path).lower() or needle in path.lower():\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "def parse_file_and_query(raw: str):\n",
    "    if \"|\" not in raw:\n",
    "        return None, raw.strip().strip(\"'\").strip('\"')\n",
    "    file_part, q = [x.strip() for x in raw.split(\"|\", 1)]\n",
    "    return resolve_doc_path(file_part), q.strip().strip(\"'\").strip('\"')\n",
    "\n",
    "@tool(\"keyword_search_tool\", description=\"Search keyword inside ONE DOCX. Input: filename.docx | keyword\")\n",
    "def keyword_search_tool(raw: str) -> str:\n",
    "    logging.info(\"Tool KW SINGLE DOC used\")\n",
    "    doc_path, keyword = parse_file_and_query(raw)\n",
    "    if not doc_path:\n",
    "        return \"Provide: filename.docx | keyword (file not found)\"\n",
    "    try:\n",
    "        tool = get_docx_tool(doc_path)\n",
    "        hits = tool.run(keyword.lower())\n",
    "        return f\"\\nüìÑ {os.path.basename(doc_path)}\\n{hits}\" if hits else \"No matches in that document.\"\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Keyword search error in {doc_path}: {e}\")\n",
    "        return f\"Error during keyword search: {e}\"\n",
    "\n",
    "@tool(\"vector_search_tool\", description=\"Semantic search inside ONE DOCX. Input: filename.docx | query\")\n",
    "def vector_search_tool(raw: str) -> str:\n",
    "    logging.info(\"Tool VECTOR SINGLE DOC used\")\n",
    "    doc_path, query = parse_file_and_query(raw)\n",
    "    if not doc_path:\n",
    "        return \"Provide: filename.docx | semantic query (file not found)\"\n",
    "    try:\n",
    "        tool = get_docx_tool(doc_path)\n",
    "        hits = tool.run(query)\n",
    "        return f\"\\nüìÑ {os.path.basename(doc_path)}\\n{hits}\" if hits else \"No semantic matches in that document.\"\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Vector search error in {doc_path}: {e}\")\n",
    "        return f\"Error during vector search: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f60458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import FileWriterTool\n",
    "@tool(\n",
    "    \"file_write_tool\",\n",
    "    description=\"Use this tool to write text to a file. Input must be: filename | content. The file will be created in the working directory.\"\n",
    ")\n",
    "def file_write_tool(input_str: str) -> str:\n",
    "    \"\"\"Writes content into a file using CrewAI's FileWriterTool.\"\"\"\n",
    "    logging.info(\"Tool File Writer used\")\n",
    "\n",
    "    # Check format\n",
    "    if \"|\" not in input_str:\n",
    "        return (\n",
    "            \"Format error. Use: filename | content\\n\"\n",
    "            \"Example: notes.txt | This is the content to write.\"\n",
    "        )\n",
    "\n",
    "    filename, content = [\n",
    "        x.strip().strip(\"'\").strip('\"')\n",
    "        for x in input_str.split(\"|\", 1)\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        writer = FileWriterTool()\n",
    "        path = writer._run(filename=filename, text=content)\n",
    "        return f\"File written successfully: {path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing file: {e}\"\n",
    "\n",
    "\n",
    "@tool(\n",
    "    \"summarize_tool\",\n",
    "    description=\"Use this tool ONLY when the user asks for a summary of a specific document. Input must be the exact filename or any part of it. The tool loads the document text internally and returns a concise 10-sentence summary.\"\n",
    ")\n",
    "def summarize_tool(input_data: str) -> str:\n",
    "    logging.info(\"Tool Summariser used\")\n",
    "    clean = input_data.strip().strip(\"'\").strip('\"').lower()\n",
    "\n",
    "    # Search in DOCS_RAW (per-file structure)\n",
    "    for d in DOCS_RAW:\n",
    "        fname = d[\"file\"].lower()\n",
    "        if clean == os.path.basename(fname) or clean in fname:\n",
    "            input_data = d[\"text\"]\n",
    "            break\n",
    "    else:\n",
    "        return f\"Document '{clean}' not found in loaded documents.\"\n",
    "\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "        summary = llm.invoke(f\"Write a summary in 10 sentences about :\\n\\n{input_data}\").content\n",
    "        return summary or \"LLM returned an empty summary. Try again later.\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"LLM invocation failed: {e}\")\n",
    "        return f\"Error during summary generation: {e}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tool(\n",
    "    \"compare_texts_tool\",\n",
    "    description=\"Use this tool to compare two texts. Input must be: textA | textB. The tool returns a detailed comparison of similarities and differences.\"\n",
    ")\n",
    "def compare_texts_tool(input_str: str) -> str:\n",
    "    logging.info(\"Tool Compare Texts used\")\n",
    "\n",
    "    # Validate the format\n",
    "    if \"|\" not in input_str:\n",
    "        return (\n",
    "            \"Format error. Use: textA | textB\\n\"\n",
    "            \"Example: 'policy text A' | 'policy text B'\"\n",
    "        )\n",
    "\n",
    "    textA, textB = [x.strip().strip(\"'\").strip('\"') for x in input_str.split(\"|\", 1)]\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Compare the two texts below in a clear, structured way.\n",
    "\n",
    "Your comparison MUST include:\n",
    "1. A summary of what each text is about.\n",
    "2. A list of key similarities.\n",
    "3. A list of key differences.\n",
    "4. Any differences in tone, structure, detail, or perspective.\n",
    "5. A short final conclusion comparing their overall purpose and message.\n",
    "\n",
    "TEXT A:\n",
    "{textA}\n",
    "\n",
    "TEXT B:\n",
    "{textB}\n",
    "\"\"\"\n",
    "\n",
    "    return llm.invoke(prompt).content\n",
    "\n",
    "@tool(\n",
    "    \"format_text_tool\",\n",
    "    description=\"Use this tool to clean, rewrite, and professionally format any text using an LLM. Input is raw text; output is a polished, well-structured version.\"\n",
    ")\n",
    "def format_text_tool(input_data: str) -> str:\n",
    "    \"\"\"Formats and rewrites text using an LLM to improve clarity, flow, and structure.\"\"\"\n",
    "    logging.info(\"Tool Format Text used\")\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Rewrite and clean the following text. Your output MUST:\n",
    "\n",
    "- Fix spacing, punctuation, and structure.\n",
    "- Keep meaning identical.\n",
    "- Improve clarity and flow.\n",
    "- Use consistent tone and formatting.\n",
    "- Break into clean sentences and paragraphs where needed.\n",
    "\n",
    "TEXT TO FORMAT:\n",
    "{input_data}\n",
    "\"\"\"\n",
    "\n",
    "    return llm.invoke(prompt).content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2511306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000,\n",
    "    timeout=30\n",
    ")\n",
    "\n",
    "reader_agent = create_agent(\n",
    "    model,\n",
    "    tools=[wordcount_tool, keyword_search_tool, vector_search_tool, news_search_tool, websearch_tool],\n",
    "    system_prompt=(\n",
    "        \"You are SEARCHER, a retrieval specialist. \"\n",
    "        \"Your ONLY job is to decide which retrieval tool is appropriate and then call it. \"\n",
    "        \"Follow these strict rules:\\n\\n\"\n",
    "        \n",
    "        \"1. Use wordcount_tool ONLY when the user explicitly asks for a word count.\\n\"\n",
    "        \"2. Use keyword_search_tool ONLY for literal keyword searches INSIDE a specific DOCX file. \"\n",
    "        \"Input MUST be formatted as: filename.docx | keyword.\\n\"\n",
    "        \"3. Use vector_search_tool ONLY for semantic search INSIDE a specific DOCX file. \"\n",
    "        \"Input MUST be formatted as: filename.docx | semantic query.\\n\"\n",
    "        \"4. Use news_search_tool ONLY when the user asks about recent news or news articles.\\n\"\n",
    "        \"5. Use websearch_tool for general internet questions that are not news-specific.\\n\\n\"\n",
    "        \n",
    "        \"Do NOT summarize. Do NOT rewrite. Do NOT generate your own content. \"\n",
    "        \"Your job is retrieval ONLY. If the user request is not about retrieving information, you MUST NOT answer directly‚Äîjust choose the correct tool.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "writer_agent = create_agent(\n",
    "    model,\n",
    "    tools=[summarize_tool, compare_texts_tool, format_text_tool, file_write_tool],\n",
    "    system_prompt=(\n",
    "        \"You are WriterBot, a writing, formatting, and document-editing specialist. \"\n",
    "        \"Your job is to select exactly ONE tool for each request.\\n\\n\"\n",
    "        \n",
    "        \"TOOL SELECTION RULES:\\n\\n\"\n",
    "\n",
    "        \"1. summarize_tool\\n\"\n",
    "        \"- Use this tool when the user wants a summary of a document or a block of text.\\n\"\n",
    "        \"- Input is plain text or a filename.\\n\\n\"\n",
    "\n",
    "        \"2. compare_texts_tool\\n\"\n",
    "        \"- Use this tool ONLY when the user provides two texts OR two filenames separated by '|'.\\n\"\n",
    "        \"- Example format: textA | textB\\n\"\n",
    "        \"- The goal is to compare similarities and differences.\\n\\n\"\n",
    "\n",
    "        \"3. format_text_tool\\n\"\n",
    "        \"- Use this tool when the user wants text cleaned, rewritten, improved, or formatted.\\n\"\n",
    "        \"- Input is a single block of text.\\n\\n\"\n",
    "\n",
    "        \"4. file_write_tool\\n\"\n",
    "        \"- Use this tool when the user wants to write text into a file.\\n\"\n",
    "        \"- Input MUST be: filename | content\\n\"\n",
    "        \"- Example: notes.txt | This is the text to save.\\n\\n\"\n",
    "\n",
    "        \"ROUTING RULES:\\n\\n\"\n",
    "        \"- Choose only ONE tool for each request.\\n\"\n",
    "        \"- Never attempt to answer using the model alone.\\n\"\n",
    "        \"- Never combine or chain tools.\\n\"\n",
    "        \"- If the user request does not follow the correct input format for any tool, ask the user to rewrite the request.\\n\"\n",
    "        \"- Your responses must always be a direct tool call.\\n\\n\"\n",
    "\n",
    "        \"You do not generate text directly. You only select tools.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b469008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "def extract_output(result):\n",
    "    try:\n",
    "        # LangChain agent output format: result[\"messages\"] is a list of messages\n",
    "        if isinstance(result, dict) and \"messages\" in result:\n",
    "            messages = result[\"messages\"]\n",
    "\n",
    "            # 1. Look for last ToolMessage (tool output)\n",
    "            for msg in reversed(messages):\n",
    "                if isinstance(msg, dict):\n",
    "                    if msg.get(\"type\") == \"tool\" and msg.get(\"content\"):\n",
    "                        return msg[\"content\"]\n",
    "                elif hasattr(msg, \"type\") and msg.type == \"tool\" and hasattr(msg, \"content\"):\n",
    "                    return msg.content\n",
    "\n",
    "            # 2. Fall back to last assistant (AI) message\n",
    "            for msg in reversed(messages):\n",
    "                if isinstance(msg, dict):\n",
    "                    if msg.get(\"role\") == \"assistant\" and msg.get(\"content\"):\n",
    "                        return msg[\"content\"]\n",
    "                elif hasattr(msg, \"role\") and msg.role == \"assistant\" and hasattr(msg, \"content\"):\n",
    "                    return msg.content\n",
    "\n",
    "            return \"No output message found.\"\n",
    "\n",
    "        # Fallback: single message or AIMessage object\n",
    "        if hasattr(result, \"content\"):\n",
    "            return result.content\n",
    "\n",
    "        return str(result)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Failed to extract output: {e}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tool(\n",
    "    \"call_reader\",\n",
    "    description=\"Call the Reader Agent to retrieve information.\"\n",
    ")\n",
    "def call_reader(query: str):\n",
    "    result = reader_agent.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
    "    })\n",
    "    return extract_output(result)\n",
    "\n",
    "\n",
    "@tool(\n",
    "    \"call_writer\",\n",
    "    description=\"Call the Writer Agent to summarize or rewrite content.\"\n",
    ")\n",
    "def call_writer(query: str):\n",
    "    result = writer_agent.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
    "    })\n",
    "    return extract_output(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "658217a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_agent = create_agent(\n",
    "    model,\n",
    "    tools=[call_reader, call_writer],\n",
    "    system_prompt=(\n",
    "        \"You are the SUPERVISOR. Your only job is to choose whether to use the reader or writer agent based on the user's request.\\n\\n\"\n",
    "        \n",
    "        \"ROUTING RULES:\\n\\n\"\n",
    "        \"- If the request involves summarizing, shortening, condensing, explaining, rewriting, formatting, cleaning, improving text, or comparing two texts ‚Üí ALWAYS call `call_writer`.\\n\"\n",
    "        \"- If the request involves retrieving, searching, looking up, finding, keyword matching, semantic understanding, reading documents, web queries, or news ‚Üí ALWAYS call `call_reader`.\\n\\n\"\n",
    "\n",
    "        \"NEVER try to answer the user's request yourself.\\n\"\n",
    "        \"NEVER call both tools. Choose only one.\\n\"\n",
    "        \"Be strict in following the routing rules. DO NOT guess.\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9c847da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Tool Word count used\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document 'Module 1 Lesson 3 Compliance legal and ethical considerations.docx' contains 113 words.\n"
     ]
    }
   ],
   "source": [
    "query = \"Count the number of words in 'Module 1 Lesson 3 Compliance legal and ethical considerations.docx'\"\n",
    "response = root_agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":query}]})\n",
    "print(extract_output(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e30ba99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Tool Summariser used\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The course \"Become a Market Leader through Reproductive and Fertility Health\" includes a module focused on compliance, legal, and ethical considerations in reproductive health at work. In Lesson 3, participants explore the legal landscape in the UK and Europe, highlighting key regulations such as the Equality Act 2010, which protects against pregnancy and maternity discrimination. Landmark cases, such as those involving Mitie Ltd and Event Medical Group, illustrate the consequences of failing to comply with these laws, resulting in significant financial penalties for employers. The Employment Rights Act 1996 and the Health and Safety at Work Act 1974 further emphasize the need for workplace adjustments for reproductive health conditions. The module also covers the EU Work-Life Balance Directive and the Pregnant Workers Directive, which set minimum rights for parental leave and protections for pregnant employees. Recent legal cases demonstrate the financial and reputational damage companies face when they fail to accommodate employees with reproductive health issues, such as endometriosis or fertility treatments. Ethical considerations are also discussed, emphasizing the importance of fairness, privacy, and equal access to reproductive health benefits. The course encourages organizations to adopt proactive reproductive health policies to improve employee satisfaction and reduce turnover-related costs. An interactive case study allows participants to analyze a real-world scenario, fostering discussion on risk mitigation and the implementation of effective policies. The session concludes with a Q&A, reinforcing the importance of legally sound and ethical reproductive health practices in the workplace.\n"
     ]
    }
   ],
   "source": [
    "query = \"Summarize the document 'Module 1 Lesson 3 Compliance legal and ethical considerations.docx'\"\n",
    "response = root_agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":query}]})\n",
    "print(extract_output(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53c499a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Tool KW SINGLE DOC used\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mUsing Tool: Search a DOCX's content\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document \"Case Study How Company X Implemented a Reproductive and Fertility Health Guide.docx\" includes a discussion on IVF, focusing on cultural and religious considerations globally. It also features a case study of the NatWest Group in the UK, which provides fertility benefits, including IVF support.\n"
     ]
    }
   ],
   "source": [
    "query = \"Case Study How Company X Implemented a Reproductive and Fertility Health Guide.docx | IVF\"\n",
    "response = root_agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":query}]})\n",
    "print(extract_output(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a5f63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Tool VECTOR SINGLE DOC used\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mUsing Tool: Search a DOCX's content\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The semantic search on the document \"Case Study How Company X Implemented a Reproductive and Fertility Health Guide.docx\" for \"IVF\" reveals that the document discusses the implementation of reproductive health-inclusive workplace policies, including IVF support. It covers cultural and religious considerations, workplace impacts, and includes case studies like the NatWest Group in the UK, which provides fertility benefits such as IVF support.\n"
     ]
    }
   ],
   "source": [
    "query = \"Perform a semantic search on Case Study How Company X Implemented a Reproductive and Fertility Health Guide.docx | IVF\"\n",
    "response = root_agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":query}]})\n",
    "print(extract_output(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4424a2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Tool Web Search used (Tavily)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some resources on medical ethics guidelines for IVF treatments:\n",
      "\n",
      "1. **Revisiting Selected Ethical Aspects of Current Clinical In Vitro**: This article discusses the ethical responsibilities of physicians and IVF centers, focusing on principles like beneficence, non-maleficence, respect for patient autonomy, and justice. [Read more](https://pmc.ncbi.nlm.nih.gov/articles/PMC8995227/)\n",
      "\n",
      "2. **Use of In Vitro Fertilization‚ÄîEthical Issues**: This review covers ethical aspects such as upper age limits, ownership of gametes and embryos, IVF in single women and same-sex couples, preimplantation genetic testing, social egg freezing, commercialization, public funding, and prioritization of IVF. [Read more](https://pmc.ncbi.nlm.nih.gov/articles/PMC7721055/)\n",
      "\n",
      "3. **Global Ethics in IVF: Harmonizing Regulation, Ensuring Access**: This article proposes a WHO-convened global ethics framework to standardize IVF ethical practices by 2027, addressing disparities in access and regulation. [Read more](https://jivfww.scholasticahq.com/article/142396)\n",
      "\n",
      "4. **‚ÄúEthical IVF‚Äù and ‚ÄúRestorative Reproductive Medicine‚Äù**: This document discusses non-discrimination against patients with difficult-to-treat conditions or multiple causes of infertility, and against discrimination based on race or socioeconomic status. [Read more](https://www.ama-assn.org/system/files/i25-omss-resolution-6.pdf)\n",
      "\n",
      "5. **Just the Facts: ‚ÄúRestorative Reproductive Medicine‚Äù and ‚ÄúEthical IVF‚Äù**: This article critiques terms like ‚Äúrestorative reproductive medicine‚Äù and ‚Äúethical IVF‚Äù as misleading and restrictive to access to proven fertility care like IVF. [Read more](https://www.asrm.org/advocacy-and-policy/fact-sheets-and-one-pagers/just-the-facts-restorative-reproductive-medicine-and-ethical-ivf-are-misleading-terms-that-threaten-access/)\n"
     ]
    }
   ],
   "source": [
    "query = \"Search the web for medical ethics guidelines about IVF treatments.\"\n",
    "response = root_agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":query}]})\n",
    "print(extract_output(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "641a089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Tool News Search used\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mUsing Tool: Search in a specific website\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some recent news highlights about IVF:\n",
      "\n",
      "1. **Legal Cases**: There have been legal cases where companies faced repercussions for not accommodating employees undergoing IVF treatments. For instance, Mrs. Benton was dismissed after undergoing IVF treatment and suffering a miscarriage. The tribunal found she was harassed and victimized due to her IVF treatment.\n",
      "\n",
      "2. **Corporate Policies**: Companies like NatWest Group in the UK are implementing fertility benefits, including IVF support, egg freezing, and adoption assistance. They provide paid leave for fertility treatments and have dedicated networks for fertility and baby loss support.\n",
      "\n",
      "3. **Cultural and Religious Considerations**: Cultural and religious considerations significantly influence reproductive healthcare policies globally. Different regions have varying attitudes towards IVF and fertility treatments, affecting workplace policies and benefits.\n",
      "\n",
      "These developments underscore the importance of inclusive reproductive health policies in workplaces, taking into account cultural, religious, and legal aspects.\n"
     ]
    }
   ],
   "source": [
    "query = \"Search major any news about IVF.\"\n",
    "response = root_agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":query}]})\n",
    "print(extract_output(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5f50a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Tool Compare Texts used\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Summary of Each Text\n",
      "\n",
      "**Text A:**  \n",
      "Text A discusses the factors influencing the success of in vitro fertilization (IVF), specifically highlighting the importance of age and medical history. It suggests that these two elements play a crucial role in determining the likelihood of a successful pregnancy through IVF.\n",
      "\n",
      "**Text B:**  \n",
      "Text B focuses on the variability of fertility outcomes based on age, emphasizing that younger patients tend to have significantly higher chances of successful IVF compared to older patients. It presents a more specific observation about the relationship between age and fertility success rates.\n",
      "\n",
      "### Key Similarities\n",
      "\n",
      "1. **Subject Matter:** Both texts address the topic of IVF and its success rates.\n",
      "2. **Focus on Age:** Each text acknowledges the impact of age on fertility outcomes.\n",
      "3. **Implication of Variability:** Both texts imply that success rates are not uniform and can differ based on certain factors.\n",
      "\n",
      "### Key Differences\n",
      "\n",
      "1. **Scope of Discussion:**  \n",
      "   - Text A is broader, mentioning both age and medical history as factors affecting IVF success.  \n",
      "   - Text B is narrower, concentrating solely on age as a determinant of fertility outcomes.\n",
      "\n",
      "2. **Detail Level:**  \n",
      "   - Text A provides a more general overview of factors influencing IVF success.  \n",
      "   - Text B offers a specific comparison between age groups, particularly highlighting the advantages of younger patients.\n",
      "\n",
      "3. **Focus on Patient Demographics:**  \n",
      "   - Text A does not specify which age groups are being discussed.  \n",
      "   - Text B explicitly states that younger patients have higher chances of success.\n",
      "\n",
      "### Differences in Tone, Structure, Detail, or Perspective\n",
      "\n",
      "- **Tone:**  \n",
      "  - Text A has a more neutral and informative tone, presenting a general statement about IVF success factors.  \n",
      "  - Text B has a more assertive tone, making a clear statement about the advantages of being younger in the context of IVF success.\n",
      "\n",
      "- **Structure:**  \n",
      "  - Text A is structured as a broad statement, while Text B is structured to highlight a specific comparison, making it more direct and focused.\n",
      "\n",
      "- **Detail:**  \n",
      "  - Text A lacks specific data or examples, whereas Text B implies a comparative analysis of success rates across different age groups.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "In conclusion, both texts address the important topic of IVF success rates, with a shared emphasis on the influence of age. However, Text A provides a broader perspective by including medical history as a factor, while Text B narrows its focus to emphasize the advantages of younger patients. The overall purpose of both texts is to inform readers about the factors affecting IVF success, but Text B delivers a more pointed message regarding the significance of age in fertility outcomes.\n"
     ]
    }
   ],
   "source": [
    "query = \"Compare the following two texts | Text A: ‚ÄúIVF success often depends on age and medical history.‚Äù | Text B: ‚ÄúFertility outcomes vary widely across age groups, with younger patients having higher chances.‚Äù.\"\n",
    "response = root_agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":query}]})\n",
    "print(extract_output(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed10a814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Tool Format Text used\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the formatted text:\n",
      "\n",
      "\"IVF is a complicated process that often involves multiple stages. Employees may require support during this time, but companies do not always understand how to provide assistance.\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Format this text: ‚Äúivf is a complicated procesS , often involving multiple stages. sometimes employees need support but companies dont always understand how to help.‚Äù\"\n",
    "response = root_agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":query}]})\n",
    "print(extract_output(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
